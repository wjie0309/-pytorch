{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afe1cdd9",
   "metadata": {},
   "source": [
    "# 第四章 基础实战——FashionMNIST时装分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951e39b",
   "metadata": {},
   "source": [
    "<img src=\"./fashion-mnist-sprite.png\" width=\"400\" />  \n",
    "  \n",
    "经过前面三章内容的学习，我们完成了以下的内容：  \n",
    "- 对PyTorch有了初步的认识\n",
    "- 学会了如何安装PyTorch以及对应的编程环境\n",
    "- 学习了PyTorch最核心的理论基础（张量&自动求导）\n",
    "- 梳理了利用PyTorch完成深度学习的主要步骤和对应实现方式  \n",
    "  \n",
    "现在，我们通过一个基础实战案例，将第一部分所涉及的PyTorch入门知识串起来，便于大家加深理解。同时为后续的进阶学习打好基础。 \n",
    "  \n",
    "我们这里的任务是对10个类别的“时装”图像进行分类，使用FashionMNIST数据集（https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion ）。上图给出了FashionMNIST中数据的若干样例图，其中每个小图对应一个样本。  \n",
    "FashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。每张图像均为单通道黑白图像，大小为32\\*32pixel，分属10个类别。  \n",
    "  \n",
    "下面让我们一起将第三章各部分内容逐步实现，来跑完整个深度学习流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e6938",
   "metadata": {},
   "source": [
    "**首先导入必要的包**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713a04db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b589c6",
   "metadata": {},
   "source": [
    "**配置训练环境和超参数**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc79b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU，这里有两种方式\n",
    "## 方案一：使用os.environ\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 256\n",
    "num_workers = 0   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b8248",
   "metadata": {},
   "source": [
    "**数据读入和加载**  \n",
    "这里同时展示两种方式:  \n",
    "- 下载并使用PyTorch提供的内置数据集  \n",
    "- 从网站下载以csv格式存储的数据，读入并转成预期的格式    \n",
    "第一种数据读入方式只适用于常见的数据集，如MNIST，CIFAR10等，PyTorch官方提供了数据下载。这种方式往往适用于快速测试方法（比如测试下某个idea在MNIST数据集上是否有效）  \n",
    "第二种数据读入方式需要自己构建Dataset，这对于PyTorch应用于自己的工作中十分重要  \n",
    "  \n",
    "同时，还需要对数据进行必要的变换，比如说需要将图片统一为一致的大小，以便后续能够输入网络训练；需要将数据格式转为Tensor类，等等。\n",
    "  \n",
    "这些变换可以很方便地借助torchvision包来完成，这是PyTorch官方用于图像处理的工具库，上面提到的使用内置数据集的方式也要用到。PyTorch的一大方便之处就在于它是一整套“生态”，有着官方和第三方各个领域的支持。这些内容我们会在后续课程中详细介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1e4e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),   # 这一步取决于后续的数据读取方式，如果使用内置数据集则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f18b5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97bee967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './FashionMNIST/fashion-mnist_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n\u001b[1;32m---> 23\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./FashionMNIST/fashion-mnist_train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FashionMNIST/fashion-mnist_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m train_data \u001b[38;5;241m=\u001b[39m FMDataset(train_df, data_transform)\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\ProgramFiles\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './FashionMNIST/fashion-mnist_train.csv'"
     ]
    }
   ],
   "source": [
    "## 读取方式二：读入csv格式的数据，自行构建Dataset类\n",
    "# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00576367",
   "metadata": {},
   "source": [
    "在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24379a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492014e",
   "metadata": {},
   "source": [
    "读入后，我们可以做一些数据可视化操作，主要是验证我们读入的数据是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0d7896c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b0adab3d60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ec586",
   "metadata": {},
   "source": [
    "**模型设计**  \n",
    "由于任务较为简单，这里我们手搭一个CNN，而不考虑当下各种模型的复杂结构  \n",
    "模型构建完成后，将模型放到GPU上用于训练  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88604c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法，之后的课程中会进一步讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb785e",
   "metadata": {},
   "source": [
    "**设定损失函数**  \n",
    "使用torch.nn模块自带的CrossEntropy损失  \n",
    "PyTorch会自动把整数型的label转为one-hot型，用于计算CE loss  \n",
    "这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f0a6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e98d1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `nn.CrossEntropyLoss # 这里方便看一下weighting等策略` not found.\n"
     ]
    }
   ],
   "source": [
    "?nn.CrossEntropyLoss # 这里方便看一下weighting等策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3380571",
   "metadata": {},
   "source": [
    "**设定优化器**  \n",
    "这里我们使用Adam优化器  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "570b5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45193548",
   "metadata": {},
   "source": [
    "**训练和测试（验证）**  \n",
    "各自封装成函数，方便后续调用  \n",
    "关注两者的主要区别：  \n",
    "- 模型状态设置  \n",
    "- 是否需要初始化优化器\n",
    "- 是否需要将loss传回到网络\n",
    "- 是否需要每步更新optimizer  \n",
    "  \n",
    "此外，对于测试或验证过程，可以计算分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aec9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6847ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):       \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fed16cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.662369\n",
      "Epoch: 1 \tValidation Loss: 0.477593, Accuracy: 0.828900\n",
      "Epoch: 2 \tTraining Loss: 0.417999\n",
      "Epoch: 2 \tValidation Loss: 0.370970, Accuracy: 0.867000\n",
      "Epoch: 3 \tTraining Loss: 0.355562\n",
      "Epoch: 3 \tValidation Loss: 0.321757, Accuracy: 0.884700\n",
      "Epoch: 4 \tTraining Loss: 0.323759\n",
      "Epoch: 4 \tValidation Loss: 0.305721, Accuracy: 0.889700\n",
      "Epoch: 5 \tTraining Loss: 0.301573\n",
      "Epoch: 5 \tValidation Loss: 0.299675, Accuracy: 0.890300\n",
      "Epoch: 6 \tTraining Loss: 0.287032\n",
      "Epoch: 6 \tValidation Loss: 0.275260, Accuracy: 0.901600\n",
      "Epoch: 7 \tTraining Loss: 0.267980\n",
      "Epoch: 7 \tValidation Loss: 0.270146, Accuracy: 0.903000\n",
      "Epoch: 8 \tTraining Loss: 0.256404\n",
      "Epoch: 8 \tValidation Loss: 0.268620, Accuracy: 0.899900\n",
      "Epoch: 9 \tTraining Loss: 0.252732\n",
      "Epoch: 9 \tValidation Loss: 0.268241, Accuracy: 0.898800\n",
      "Epoch: 10 \tTraining Loss: 0.240475\n",
      "Epoch: 10 \tValidation Loss: 0.249730, Accuracy: 0.908700\n",
      "Epoch: 11 \tTraining Loss: 0.232593\n",
      "Epoch: 11 \tValidation Loss: 0.241084, Accuracy: 0.912400\n",
      "Epoch: 12 \tTraining Loss: 0.219880\n",
      "Epoch: 12 \tValidation Loss: 0.242226, Accuracy: 0.914000\n",
      "Epoch: 13 \tTraining Loss: 0.214687\n",
      "Epoch: 13 \tValidation Loss: 0.235402, Accuracy: 0.914500\n",
      "Epoch: 14 \tTraining Loss: 0.209356\n",
      "Epoch: 14 \tValidation Loss: 0.242320, Accuracy: 0.911200\n",
      "Epoch: 15 \tTraining Loss: 0.203261\n",
      "Epoch: 15 \tValidation Loss: 0.241792, Accuracy: 0.910300\n",
      "Epoch: 16 \tTraining Loss: 0.195212\n",
      "Epoch: 16 \tValidation Loss: 0.249070, Accuracy: 0.910400\n",
      "Epoch: 17 \tTraining Loss: 0.189653\n",
      "Epoch: 17 \tValidation Loss: 0.233456, Accuracy: 0.916000\n",
      "Epoch: 18 \tTraining Loss: 0.185264\n",
      "Epoch: 18 \tValidation Loss: 0.236951, Accuracy: 0.916000\n",
      "Epoch: 19 \tTraining Loss: 0.178915\n",
      "Epoch: 19 \tValidation Loss: 0.234369, Accuracy: 0.919400\n",
      "Epoch: 20 \tTraining Loss: 0.173203\n",
      "Epoch: 20 \tValidation Loss: 0.227856, Accuracy: 0.919100\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b243e56",
   "metadata": {},
   "source": [
    "**模型保存**  \n",
    "训练完成后，可以使用torch.save保存模型参数或者整个模型，也可以在训练过程中保存模型  \n",
    "这部分会在后面的课程中详细介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f86ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625670b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
